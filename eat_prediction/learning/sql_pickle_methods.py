
# coding: utf-8

# In[ ]:

import csv
import string
import pickle
import pandas as pd
import datetime as dt
import uuid
import os
import psycopg2
import sys
import sklearn
import threading
import numpy as np
import matplotlib.pyplot as plt
from sklearn import *
from sklearn.metrics import *
from sklearn.linear_model import *
from sklearn.model_selection import *

def get_redshift_conn(redshift_username,redshift_password):
    params_rs = {
    'database': 'datawarehouse',
    'user': redshift_username,
    'password': redshift_password,
    'host': 'dwv1.redshift.yelpcorp.com',
    'port': '5439',
    'sslmode': 'require'} 
    conn = psycopg2.connect(**params_rs)
    return conn


def get_df_from_query(sqlname,redshift_username,redshift_password,replacements={}):
    conn = get_redshift_conn(redshift_username,redshift_password)
    cur = conn.cursor()  
    query_path = os.path.abspath(os.path.join(os.pardir, 'queries/',sqlname)) #runs query stored at sqlname
    sql_file = open(query_path,'rb')
    sql_str = sql_file.read()
    print sql_str
    for original_str, replace_with in replacements.iteritems():
        sql_str = string.replace(sql_str,original_str,replace_with)
    print sql_str
    sql_file.close()
    cur.execute(sql_str) 
    conn.commit()
    df = pd.read_sql(sql_str,conn)
    conn.close()
    return df
    
#saves a dataframe generated by a sqlquery to pickle file 
def save_query_to_csv(sqlname,csv_filename,redshift_username,redshift_password,replacements={}):
    df = get_df_from_query(sqlname,redshift_username,redshift_password,replacements)
    df.to_csv(csv_filename + '.csv')
    return df
    
def save_dprovider_to_csv(dprovider_name,zone_number,startdate,enddate):
    replacements ={"&replace1":startdate,"&replace2":enddate,"&replacedprovider&":dprovider_name,"&replacedzonenumber&":zone_number}
    sql_filename = "Dakota_run_model30_dproviders.sql"
    csv_filename = dprovider_name.replace(" ","_")
    dprovider_df = save_query_to_csv(sql_filename,csv_filename,replacements)
    return dprovider_df

def get_dprovider_zones(dprovider_name):
    sql_filename = "get_dprovider_zones.sql"
    replacements = {"&replacedprovider&":dprovider_name}
    zones_df = get_df_from_query(sql_filename,replacements)
    return zones_df
    
def load_pickle(picklename):
	pickle_file = open(picklename, 'r')
	df = pickle.load(pickle_file)
	df = pd.DataFrame(df)
	pickle_file.close()
	return df